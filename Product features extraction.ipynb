{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf216e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "import spacy\n",
    "from webcolors import CSS3_NAMES_TO_HEX\n",
    "\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "from Helpers.helpers import preprocess_description, preprocess_specification_column, reg_extract, reg_extract_color, spacy_extract,preprocess_training_examples,preprocess_validation_examples\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccd66d",
   "metadata": {},
   "source": [
    "# Data Loading and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ede8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pandas.read_csv(\"marketing_sample_for_amazon_com-ecommerce_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13f5aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniq Id</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Asin</th>\n",
       "      <th>Category</th>\n",
       "      <th>Upc Ean Code</th>\n",
       "      <th>List Price</th>\n",
       "      <th>Selling Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Model Number</th>\n",
       "      <th>...</th>\n",
       "      <th>Product Url</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Product Details</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Color</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Direction To Use</th>\n",
       "      <th>Is Amazon Seller</th>\n",
       "      <th>Size Quantity Variant</th>\n",
       "      <th>Product Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4c69b61db1fc16e7013b43fc926e502d</td>\n",
       "      <td>DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sports &amp; Outdoors | Outdoor Recreation | Skate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$237.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/DB-Longboards-CoreFlex-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66d49bbed043f5be260fa9f7fbff5957</td>\n",
       "      <td>Electronic Snap Circuits Mini Kits Classpack, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toys &amp; Games | Learning &amp; Education | Science ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$99.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55324</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/Electronic-Circuits-Cla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2c55cae269aebf53838484b0d7dd931a</td>\n",
       "      <td>3Doodler Create Flexy 3D Printing Filament Ref...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toys &amp; Games | Arts &amp; Crafts | Craft Kits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$34.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/3Doodler-Plastic-Innova...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18018b6bc416dab347b1b7db79994afa</td>\n",
       "      <td>Guillow Airplane Design Studio with Travel Cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toys &amp; Games | Hobbies | Models &amp; Model Kits |...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$28.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/Guillow-Airplane-Design...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e04b990e95bf73bbe6a3fa09785d7cd0</td>\n",
       "      <td>Woodstock- Collage 500 pc Puzzle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toys &amp; Games | Puzzles | Jigsaw Puzzles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$17.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62151</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/Woodstock-Collage-500-p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Uniq Id  \\\n",
       "0  4c69b61db1fc16e7013b43fc926e502d   \n",
       "1  66d49bbed043f5be260fa9f7fbff5957   \n",
       "2  2c55cae269aebf53838484b0d7dd931a   \n",
       "3  18018b6bc416dab347b1b7db79994afa   \n",
       "4  e04b990e95bf73bbe6a3fa09785d7cd0   \n",
       "\n",
       "                                        Product Name  Brand Name  Asin  \\\n",
       "0  DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...         NaN   NaN   \n",
       "1  Electronic Snap Circuits Mini Kits Classpack, ...         NaN   NaN   \n",
       "2  3Doodler Create Flexy 3D Printing Filament Ref...         NaN   NaN   \n",
       "3  Guillow Airplane Design Studio with Travel Cas...         NaN   NaN   \n",
       "4                   Woodstock- Collage 500 pc Puzzle         NaN   NaN   \n",
       "\n",
       "                                            Category Upc Ean Code  List Price  \\\n",
       "0  Sports & Outdoors | Outdoor Recreation | Skate...          NaN         NaN   \n",
       "1  Toys & Games | Learning & Education | Science ...          NaN         NaN   \n",
       "2          Toys & Games | Arts & Crafts | Craft Kits          NaN         NaN   \n",
       "3  Toys & Games | Hobbies | Models & Model Kits |...          NaN         NaN   \n",
       "4            Toys & Games | Puzzles | Jigsaw Puzzles          NaN         NaN   \n",
       "\n",
       "  Selling Price  Quantity Model Number  ...  \\\n",
       "0       $237.68       NaN          NaN  ...   \n",
       "1        $99.95       NaN        55324  ...   \n",
       "2        $34.99       NaN          NaN  ...   \n",
       "3        $28.91       NaN          142  ...   \n",
       "4        $17.49       NaN        62151  ...   \n",
       "\n",
       "                                         Product Url Stock Product Details  \\\n",
       "0  https://www.amazon.com/DB-Longboards-CoreFlex-...   NaN             NaN   \n",
       "1  https://www.amazon.com/Electronic-Circuits-Cla...   NaN             NaN   \n",
       "2  https://www.amazon.com/3Doodler-Plastic-Innova...   NaN             NaN   \n",
       "3  https://www.amazon.com/Guillow-Airplane-Design...   NaN             NaN   \n",
       "4  https://www.amazon.com/Woodstock-Collage-500-p...   NaN             NaN   \n",
       "\n",
       "  Dimensions Color Ingredients Direction To Use  Is Amazon Seller  \\\n",
       "0        NaN   NaN         NaN              NaN                 Y   \n",
       "1        NaN   NaN         NaN              NaN                 Y   \n",
       "2        NaN   NaN         NaN              NaN                 Y   \n",
       "3        NaN   NaN         NaN              NaN                 Y   \n",
       "4        NaN   NaN         NaN              NaN                 Y   \n",
       "\n",
       "  Size Quantity Variant  Product Description  \n",
       "0                   NaN                  NaN  \n",
       "1                   NaN                  NaN  \n",
       "2                   NaN                  NaN  \n",
       "3                   NaN                  NaN  \n",
       "4                   NaN                  NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff143a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10002, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc19e42",
   "metadata": {},
   "source": [
    "Unstructured data, empty columns and missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b8d11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10002 entries, 0 to 10001\n",
      "Data columns (total 28 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Uniq Id                10002 non-null  object \n",
      " 1   Product Name           10002 non-null  object \n",
      " 2   Brand Name             0 non-null      float64\n",
      " 3   Asin                   0 non-null      float64\n",
      " 4   Category               9172 non-null   object \n",
      " 5   Upc Ean Code           34 non-null     object \n",
      " 6   List Price             0 non-null      float64\n",
      " 7   Selling Price          9895 non-null   object \n",
      " 8   Quantity               0 non-null      float64\n",
      " 9   Model Number           8232 non-null   object \n",
      " 10  About Product          9729 non-null   object \n",
      " 11  Product Specification  8370 non-null   object \n",
      " 12  Technical Details      9212 non-null   object \n",
      " 13  Shipping Weight        8864 non-null   object \n",
      " 14  Product Dimensions     479 non-null    object \n",
      " 15  Image                  10002 non-null  object \n",
      " 16  Variants               2478 non-null   object \n",
      " 17  Sku                    0 non-null      float64\n",
      " 18  Product Url            10002 non-null  object \n",
      " 19  Stock                  0 non-null      float64\n",
      " 20  Product Details        0 non-null      float64\n",
      " 21  Dimensions             0 non-null      float64\n",
      " 22  Color                  0 non-null      float64\n",
      " 23  Ingredients            0 non-null      float64\n",
      " 24  Direction To Use       0 non-null      float64\n",
      " 25  Is Amazon Seller       10002 non-null  object \n",
      " 26  Size Quantity Variant  0 non-null      float64\n",
      " 27  Product Description    0 non-null      float64\n",
      "dtypes: float64(13), object(15)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7d8dd",
   "metadata": {},
   "source": [
    "Remove irrelevant columns: (Empty, redundant or the ones that don't add value in our case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dce7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [0,2,3,4,5,6,7,8,9,13,15,16,17,18,19,20,21,22,23,24,25,26,27]\n",
    "df.drop(df.columns[cols], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e66d4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10002 entries, 0 to 10001\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Product Name           10002 non-null  object\n",
      " 1   About Product          9729 non-null   object\n",
      " 2   Product Specification  8370 non-null   object\n",
      " 3   Technical Details      9212 non-null   object\n",
      " 4   Product Dimensions     479 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd574202",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4d622a",
   "metadata": {},
   "source": [
    "- The `product specification` column contains mainly the information about the dimension and weight and requires particularly preprocessing as it's unstructured.\n",
    "- The `preprocess_specification_column` function adds spaces before and after digits and key words in order to make it clearer for the POS tagging system. Example: (pre and after applying the function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be1f89eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductDimensions:10.3x3.4x0.8inches|ItemWeight:12.8ounces|ShippingWeight:12.8ounces(Viewshippingratesandpolicies)|ASIN:B07D36747F|Manufacturerrecommendedage:14yearsandup \n",
      "\n",
      " ProductDimensions : 10.3 x 3.4 x 0.8 inches | item weight : 12.8 ounces |ShippingWeight : 12.8 ounces (Viewshippingratesandpolicies)|ASIN : B07D36747F|Manufacturerrecommendedage : 14yearsandup\n"
     ]
    }
   ],
   "source": [
    "print(df['Product Specification'][2],'\\n'*2,preprocess_specification_column(df['Product Specification'][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff72ef2",
   "metadata": {},
   "source": [
    "- The `Context` column is the concatenation of all relevant columns \n",
    "- The `preprocess_description` function removes stop words, punctuation and tokens with irrelevant tags (verbs, determinants...)\n",
    "- The `Product Dimensions` (Answer) column will be used later as the answer part in a question answering task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4120dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=(\n",
    "     df\n",
    "     .fillna({'Product Name':'','About Product':'','Product Specification':'','Technical Details':''})\n",
    "     .assign(**{'Product Specification': lambda df: df['Product Specification'].apply(preprocess_specification_column),\n",
    "               'Context':lambda df: df['Product Name']+' '+df['About Product']+' '+df['Product Specification']+' '+df['Technical Details']})\n",
    "     .assign(Context=lambda df: df['Context'].apply(preprocess_description))\n",
    "     .drop(columns=['Product Name','About Product','Product Specification','Technical Details'],axis=1)\n",
    "     .rename(columns={'Product Dimensions':'Answer'})\n",
    "     \n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5002a210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41 bamboo fiberglass complete sure model numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.7 x 11.1 x 10.2 inches  4.06 pounds</td>\n",
       "      <td>electronic snap circuits mini kits radio motio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3doodler flexy 3d printing filament refill bun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>guillow airplane design studio travel case bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>collage 500 pc puzzle sure model number | puzz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Answer  \\\n",
       "0                                     NaN   \n",
       "1  14.7 x 11.1 x 10.2 inches  4.06 pounds   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "                                             Context  \n",
       "0  41 bamboo fiberglass complete sure model numbe...  \n",
       "1  electronic snap circuits mini kits radio motio...  \n",
       "2  3doodler flexy 3d printing filament refill bun...  \n",
       "3  guillow airplane design studio travel case bui...  \n",
       "4  collage 500 pc puzzle sure model number | puzz...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630f9a3",
   "metadata": {},
   "source": [
    "# Use Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbb6bb",
   "metadata": {},
   "source": [
    "Are defined below three regex patterns to extract the three wanted features which go with the preprocessing we have.<br>\n",
    "The CSS3_NAMES_TO_HEX is a color dictionary imported from the python color library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0313909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dimension_pattern = r'(\\d+(\\.\\d+)?\\s*x\\s*\\d+(\\.\\d+)?\\s*x\\s*\\d+(\\.\\d+)?\\s*inches)'\n",
    "reg_weight_pattern=r'(item weight\\s*(\\d+(\\.\\d+)?)\\s*(pounds|ounces|lbs))'\n",
    "reg_color_pattern=r'\\b(' + '|'.join(list(CSS3_NAMES_TO_HEX.keys())) + r')\\b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce19d78",
   "metadata": {},
   "source": [
    "Extracting color form context using the `reg_extract_color` function and weight and dimensions using the `reg_extract ` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45dcc177",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extracted_regex=( \n",
    "    dataset['Context'].to_frame()\n",
    "    .assign(**{'Color': lambda df: df['Context'].apply(lambda x: reg_extract_color(x,reg_color_pattern)),\n",
    "               'weight': lambda df: df['Context'].apply(lambda x: reg_extract(x,reg_weight_pattern)),\n",
    "               'Dimension': lambda df: df['Context'].apply(lambda x: reg_extract(x,reg_dimension_pattern))})\n",
    ")\n",
    "features_extracted_regex.to_excel('Extracted Features.xlsx',sheet_name='Regex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29267c5f",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d1ee587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension feature is found for:  7991  rows\n",
      "The weight feature is found for:  7483  rows\n",
      "The Color feature is found for:  3503  rows\n"
     ]
    }
   ],
   "source": [
    "nbr_dimension=len(features_extracted_regex[features_extracted_regex['Dimension'].notnull()])\n",
    "nbr_weight=len(features_extracted_regex[features_extracted_regex['weight'].notnull()])\n",
    "nbr_color=len(features_extracted_regex[features_extracted_regex['Color'].notnull()])\n",
    "print('The dimension feature is found for: ',nbr_dimension,' rows')\n",
    "print('The weight feature is found for: ',nbr_weight,' rows')\n",
    "print('The Color feature is found for: ',nbr_color, ' rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb9599",
   "metadata": {},
   "source": [
    "# Use The Spacy Library : POS based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0711ed2",
   "metadata": {},
   "source": [
    "Define rule-based patterns using POS tags and keywords:\n",
    "- Dimension: xx * xx * xx inches\n",
    "- Weight: item weight xx ( pounds ||ounces ||lbs)\n",
    "- Color: in list of colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bd8713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_pattern = [{'POS': 'NUM'},{'LOWER': 'x'},{'POS': 'NUM'},{'LOWER': 'x'}, {'POS':'NUM'},\n",
    "                     {'LOWER': 'inches'}] \n",
    "weight_pattern = [{'LOWER': 'item'},{'LOWER': 'weight'},{'POS': 'NUM'},\n",
    "                  {'LOWER': {'IN': ['ounces', 'pounds','lbs']}}]\n",
    "color_pattern=[{'LOWER': {'IN': list(CSS3_NAMES_TO_HEX.keys())}}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d4adbc",
   "metadata": {},
   "source": [
    "`spacy_extract` is a function to find patterns in a text using the SpaCy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efde4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extracted_spacy=( \n",
    "    dataset['Context'].to_frame()\n",
    "    .assign(**{'Color': lambda df: df['Context'].apply(lambda x: spacy_extract(x,color_pattern)),\n",
    "               'weight': lambda df: df['Context'].apply(lambda x: spacy_extract(x,weight_pattern)),\n",
    "               'Dimension': lambda df: df['Context'].apply(lambda x: spacy_extract(x,dimension_pattern))})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4149fee",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78017218",
   "metadata": {},
   "source": [
    "Among 10002 samples we could extract features for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d83332d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension feature is found for:  7991  rows\n",
      "The weight feature is found for:  7484  rows\n",
      "The Color feature is found for:  3495  rows\n"
     ]
    }
   ],
   "source": [
    "nbr_dimension=len(features_extracted_spacy[features_extracted_spacy['Dimension'].notnull()])\n",
    "nbr_weight=len(features_extracted_spacy[features_extracted_spacy['weight'].notnull()])\n",
    "nbr_color=len(features_extracted_spacy[features_extracted_spacy['Color'].notnull()])\n",
    "print('The dimension feature is found for: ',nbr_dimension,' rows')\n",
    "print('The weight feature is found for: ',nbr_weight,' rows')\n",
    "print('The Color feature is found for: ',nbr_color, ' rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Store results:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "writer = pandas.ExcelWriter('Extracted Features.xlsx', engine='xlsxwriter')\n",
    "features_extracted_regex.to_excel(writer, sheet_name='Regex')\n",
    "features_extracted_spacy.to_excel(writer, sheet_name='SpaCy')\n",
    "writer.save()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Observation:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "7568edef",
   "metadata": {},
   "source": [
    "The regular expressions succeeded at extracting more features in less time which is due to the structure and nature of the information we're looking for and we can't generalize this for more complicated cases where regular expressions are limited ( Entity recognition, particular linguistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f318a",
   "metadata": {},
   "source": [
    "# Use a Question Answering Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f86f68",
   "metadata": {},
   "source": [
    "Intuitively we could think of that task as a question answering task where 'context' is the product description and 'answer' is the explicit feature value we could get from a specific column (column with the same feature name). <br> In our dataset this labelling is only available for the Product Dimensions feature ( we have 479 non null values That's why we will try to use a pretrained model to answer the question \"What are the product dimensions?\" and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc6ba399",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de5b6c",
   "metadata": {},
   "source": [
    "One sample to test this pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2e44050",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=dataset['Context'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9c1a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_weight = [ \"What is the product weight?\"]\n",
    "question_color=[\"What is the product color?\"]\n",
    "question_dimension=[ \"What is the product dimensions?\"]\n",
    "context = [sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b3833",
   "metadata": {},
   "source": [
    "Answer generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beee2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(context,question):\n",
    "    input = tokenizer(question, context, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    output = model(**input)\n",
    "    start_logit, end_logit = output.start_logits, output.end_logits\n",
    "    answer_start = torch.argmax(start_logit, dim=1)\n",
    "    answer_end = torch.argmax(end_logit, dim=1) + 1\n",
    "    answer = [tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input[\"input_ids\"][0][answer_start[0]:answer_end[0]]))]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f0bb594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14. 7 x 11. 1 x 10. 2 inches']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(context,question_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dad5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=( \n",
    "    dataset['Context'].to_frame()\n",
    "    .assign(**{'Color': lambda df: df['Context'].apply(lambda x: answer_question([x],question_color)),\n",
    "               'weight': lambda df: df['Context'].apply(lambda x: answer_question([x],question_weight)),\n",
    "               'Dimension': lambda df: df['Context'].apply(lambda x: answer_question([x],question_dimension))})\n",
    ")\n",
    "results.to_excel('results.xlsx',sheet_name='QuAn')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We get numerous examples where a regular expression or a POS tags based system would fail to extract the information and this could be observed especially with the Dimensions feature because it has multiple possible patterns, examples:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['59. 8 ( l ) * 48 ( w ) * 36. 8 ( h ) / 173. 5 / nimh cells'] \n",
      " ['10 length x 0. 5 depth x 15 height inches'] \n",
      " ['49 x 32 total length 20 tail 10 x 6. 5 x | 300 x 80']\n"
     ]
    }
   ],
   "source": [
    "print(results['Dimension'][9296],'\\n',results['Dimension'][9171],'\\n',results['Dimension'][8666])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, we get many flawed predictions. That's why it's imperative to find a way to eliminate such predictions which are particularly frequent in the Color case. <br> Since fine-tuning requires important computational resources, we could prioritize features for which the pretrained model performs badly. <br>\n",
    "But in this situation, we only have labeled data for the Dimensions feature ( if we make the assumption that the values we have in the Dimensions column are correct)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "bc187c01",
   "metadata": {},
   "source": [
    "# Fine Tune on our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889e450",
   "metadata": {},
   "source": [
    "The dataset we have is tiny (479 samples: labeled data points), but the pattern is kind of obvious and repetitive, so we expect finetuning to improve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fe2bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=[\"What are the product dimensions?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bf2e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.dropna(subset=['Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5168d5",
   "metadata": {},
   "source": [
    "In order to use Hugging face transformers we need to adjust our data to the compatible form accepted by the predefined functions from Hugging face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edac3156",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5df3727d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'context', 'answer', 'question'],\n",
       "    num_rows: 479\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {'id': list(range(len(dataset))),\n",
    "             'context': dataset['Context'].tolist(),\n",
    "             'answer': dataset['Answer'].tolist(),\n",
    "             'question':question*len(dataset)}\n",
    "data = Dataset.from_dict(data_dict)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e7b8b",
   "metadata": {},
   "source": [
    "- Split the data into training and validation sets\n",
    "- Convert the sets to the compatible dataset type\n",
    "- Apply the necessary preprocessing to the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e87b7f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/383 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/96 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['id', 'context', 'answer', 'question', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "     num_rows: 383\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'context', 'answer', 'question', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "     num_rows: 96\n",
       " }))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = Dataset.from_dict(train_data),Dataset.from_dict(val_data)\n",
    "train_data, val_data = train_data.map(preprocess_training_examples, batched=True),val_data.map(preprocess_validation_examples, batched=True)\n",
    "train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de297ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0aabe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34da5d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626eda3c",
   "metadata": {},
   "source": [
    "Using the Trainer API from the Hugging face platform ( Hyperparameters tuned for the available computational resources), but still couldn't get rid of the 'Cuda out of memory' error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d93853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: answer, id, question, context. If answer, id, question, context are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 6\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 128\n",
      "  Number of trainable parameters = 334094338\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 54.00 MiB (GPU 0; 4.00 GiB total capacity; 3.42 GiB already allocated; 0 bytes free; 3.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\AMALGA~1\\AppData\\Local\\Temp/ipykernel_89352/992843150.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[0meval_dataset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval_data\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m )\n\u001B[1;32m---> 18\u001B[1;33m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1541\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_inner_training_loop\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_train_batch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_find_batch_size\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1542\u001B[0m         )\n\u001B[1;32m-> 1543\u001B[1;33m         return inner_training_loop(\n\u001B[0m\u001B[0;32m   1544\u001B[0m             \u001B[0margs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1545\u001B[0m             \u001B[0mresume_from_checkpoint\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mresume_from_checkpoint\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36m_inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   1789\u001B[0m                         \u001B[0mtr_loss_step\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1790\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1791\u001B[1;33m                     \u001B[0mtr_loss_step\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1792\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1793\u001B[0m                 if (\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36mtraining_step\u001B[1;34m(self, model, inputs)\u001B[0m\n\u001B[0;32m   2537\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2538\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompute_loss_context_manager\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2539\u001B[1;33m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompute_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2540\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2541\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_gpu\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36mcompute_loss\u001B[1;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[0;32m   2569\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2570\u001B[0m             \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2571\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2572\u001B[0m         \u001B[1;31m# Save past state if it exists\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2573\u001B[0m         \u001B[1;31m# TODO: this needs to be fixed and made cleaner later.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1849\u001B[0m         \u001B[0mreturn_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreturn_dict\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mreturn_dict\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muse_return_dict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1850\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1851\u001B[1;33m         outputs = self.bert(\n\u001B[0m\u001B[0;32m   1852\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1853\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1017\u001B[0m             \u001B[0mpast_key_values_length\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpast_key_values_length\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1018\u001B[0m         )\n\u001B[1;32m-> 1019\u001B[1;33m         encoder_outputs = self.encoder(\n\u001B[0m\u001B[0;32m   1020\u001B[0m             \u001B[0membedding_output\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1021\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mextended_attention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    607\u001B[0m                 )\n\u001B[0;32m    608\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 609\u001B[1;33m                 layer_outputs = layer_module(\n\u001B[0m\u001B[0;32m    610\u001B[0m                     \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    611\u001B[0m                     \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    493\u001B[0m         \u001B[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    494\u001B[0m         \u001B[0mself_attn_past_key_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpast_key_value\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mpast_key_value\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 495\u001B[1;33m         self_attention_outputs = self.attention(\n\u001B[0m\u001B[0;32m    496\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    497\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    423\u001B[0m         \u001B[0moutput_attentions\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mbool\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    424\u001B[0m     ) -> Tuple[torch.Tensor]:\n\u001B[1;32m--> 425\u001B[1;33m         self_outputs = self.self(\n\u001B[0m\u001B[0;32m    426\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    427\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    321\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    322\u001B[0m         \u001B[1;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 323\u001B[1;33m         \u001B[0mattention_scores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery_layer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey_layer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    324\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    325\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mposition_embedding_type\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"relative_key\"\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mposition_embedding_type\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"relative_key_query\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 54.00 MiB (GPU 0; 4.00 GiB total capacity; 3.42 GiB already allocated; 0 bytes free; 3.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,              \n",
    "    per_device_train_batch_size=6,  \n",
    "    per_device_eval_batch_size=6,   \n",
    "    warmup_steps=2,                \n",
    "    weight_decay=0.01,               \n",
    "    #logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regular expressions and rule-based pipelines can be effective for information retrieval, particularly when working with well-structured data. However, they have limitations when dealing with highly unstructured data where patterns and rules are difficult to define. Moreover, these methods may not work well when the information we seek does not follow a particular pattern. This is where Language Models (LLMs) come into play, as they can help to overcome these limitations. However, LLMs also have their own limitations, such as requiring labeled data for fine-tuning and evaluation in order to achieve high confidence scores. <br> Ensembling can be a useful approach, where multiple methods are combined to balance accuracy and performance, and the most effective method is used for each feature. It would also be worthwhile to explore unsupervised fine-tuning methods."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
